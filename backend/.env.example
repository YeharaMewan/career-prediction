# Career Planning Multi-Agent System Environment Variables

# ==================== LLM PROVIDER CONFIGURATION ====================
# Primary LLM provider: openai, gemini, or fallback
# - "openai": Use OpenAI exclusively
# - "gemini": Use Google Gemini exclusively
# - "fallback": Use OpenAI with automatic Gemini fallback
LLM_PROVIDER=openai

# Enable automatic fallback to Gemini when OpenAI fails (true/false)
ENABLE_FALLBACK=true

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o

# Google Gemini Configuration (required for fallback)
GOOGLE_API_KEY=your_google_api_key_here
GEMINI_MODEL=gemini-1.5-pro

# LLM Request Configuration
LLM_TEMPERATURE=0.1
LLM_TIMEOUT=60
LLM_MAX_RETRIES=2

# ==================== OTHER API KEYS ====================
# Tavily Search Configuration (Optional)
TAVILY_API_KEY=your_tavily_api_key_here

# LangSmith Configuration (Optional - for monitoring)
LANGSMITH_API_KEY=your_langsmith_api_key_here
LANGCHAIN_PROJECT=career-planning-system
LANGCHAIN_TRACING_V2=false

# Backend Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=false
LOG_LEVEL=INFO

# Database Configuration (if needed in future)
# DATABASE_URL=sqlite:///./career_planning.db

# Frontend Configuration
VITE_API_URL=
VITE_API_BASE=

# Docker Configuration
COMPOSE_PROJECT_NAME=career-planning